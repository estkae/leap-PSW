# COCO Dataset Download & Organisation Guide

## ğŸ¯ Schnellstart - Komplett-Pipeline

```bash
# 1. COCO Dataset herunterladen (Person & Auto)
python download_coco_dataset.py --splits train val --categories person car

# 2. In LFM2-VL Struktur organisieren
python organize_training_data.py --source coco_download/organized --target .

# 3. Fertig! Training starten
python training/train_model.py
```

## ğŸ“¥ Schritt 1: COCO Dataset Download

### Basis-Download (Person & Auto)
```bash
python download_coco_dataset.py
```

**Was passiert:**
- âœ… LÃ¤dt COCO 2017 Train-Set (~18 GB)
- âœ… LÃ¤dt COCO 2017 Val-Set (~1 GB)
- âœ… Filtert Person-Bilder
- âœ… Filtert Auto-Bilder
- âœ… Organisiert in `coco_download/organized/`

### Erweiterte Optionen

#### Nur Training-Daten
```bash
python download_coco_dataset.py --splits train
```

#### ZusÃ¤tzliche Kategorien
```bash
python download_coco_dataset.py --categories person car bicycle motorcycle
```

#### Custom Download-Verzeichnis
```bash
python download_coco_dataset.py --download-dir /path/to/download
```

#### Direktes Output-Verzeichnis
```bash
python download_coco_dataset.py --output-dir /path/to/organized
```

### Parameter-Ãœbersicht

| Parameter | Default | Beschreibung |
|-----------|---------|--------------|
| `--splits` | `train val` | Welche Splits laden |
| `--categories` | `person car` | Welche Kategorien filtern |
| `--download-dir` | `./coco_download` | Wo Downloads speichern |
| `--output-dir` | `coco_download/organized` | Wo organisierte Daten speichern |

## ğŸ“ Schritt 2: Training-Daten organisieren

### Basis-Organisation
```bash
python organize_training_data.py --source coco_download/organized
```

**Was passiert:**
- âœ… Erstellt `datatrainperson/`, `datatrainauto/`
- âœ… Erstellt `datavalperson/`, `datavalauto/`
- âœ… Erstellt `datatestperson/`, `datatestauto/`
- âœ… Split: 70% Train, 20% Val, 10% Test

### Custom Split-VerhÃ¤ltnisse
```bash
python organize_training_data.py \
  --source coco_download/organized \
  --train-ratio 0.8 \
  --val-ratio 0.15 \
  --test-ratio 0.05
```

### Nur bestimmte Kategorien
```bash
python organize_training_data.py \
  --source coco_download/organized \
  --categories person
```

### Reproduzierbare Splits
```bash
python organize_training_data.py \
  --source coco_download/organized \
  --seed 42
```

### Parameter-Ãœbersicht

| Parameter | Default | Beschreibung |
|-----------|---------|--------------|
| `--source` | (erforderlich) | Source-Verzeichnis mit COCO Daten |
| `--target` | `.` | Ziel-Verzeichnis |
| `--categories` | `person car` | Welche Kategorien organisieren |
| `--train-ratio` | `0.7` | Anteil Training (70%) |
| `--val-ratio` | `0.2` | Anteil Validation (20%) |
| `--test-ratio` | `0.1` | Anteil Test (10%) |
| `--seed` | `42` | Random Seed |

## ğŸ“Š Erwartete Datenmengen

### COCO 2017 Dataset

| Split | Gesamt | Person | Auto (ca.) |
|-------|--------|--------|-----------|
| Train | 118K Bilder | ~65K | ~12K |
| Val | 5K Bilder | ~3K | ~600 |

### Nach Organisation (70/20/10 Split)

#### Person-Kategorie
```
datatrainperson/    ~65,000 Bilder
datavalperson/      ~600 Bilder
datatestperson/     ~300 Bilder
```

#### Auto-Kategorie
```
datatrainauto/      ~12,000 Bilder
datavalauto/        ~120 Bilder
datatestauto/       ~60 Bilder
```

## ğŸ—‚ï¸ Resultierende Ordnerstruktur

```
vision-recognition/
â”œâ”€â”€ coco_download/              # Download-Verzeichnis
â”‚   â”œâ”€â”€ downloads/              # ZIP-Dateien
â”‚   â”‚   â”œâ”€â”€ train2017.zip      (~18 GB)
â”‚   â”‚   â”œâ”€â”€ val2017.zip        (~1 GB)
â”‚   â”‚   â””â”€â”€ annotations_trainval2017.zip
â”‚   â”œâ”€â”€ extracted/              # Extrahierte Daten
â”‚   â”‚   â”œâ”€â”€ train2017/
â”‚   â”‚   â”œâ”€â”€ val2017/
â”‚   â”‚   â””â”€â”€ annotations/
â”‚   â””â”€â”€ organized/              # Gefilterte Daten
â”‚       â”œâ”€â”€ train/
â”‚       â”‚   â”œâ”€â”€ person/
â”‚       â”‚   â””â”€â”€ car/
â”‚       â””â”€â”€ val/
â”‚           â”œâ”€â”€ person/
â”‚           â””â”€â”€ car/
â”‚
â”œâ”€â”€ datatrainperson/           # Training Personen
â”œâ”€â”€ datatraingesicht/          # Training Gesichter (TODO)
â”œâ”€â”€ datatrainauto/             # Training Autos
â”œâ”€â”€ datavalperson/             # Validation Personen
â”œâ”€â”€ datavalgesicht/            # Validation Gesichter (TODO)
â”œâ”€â”€ datavalauto/               # Validation Autos
â”œâ”€â”€ datatestperson/            # Test Personen
â”œâ”€â”€ datatestgesicht/           # Test Gesichter (TODO)
â””â”€â”€ datatestauto/              # Test Autos
```

## âš™ï¸ Requirements

### Python-Pakete installieren
```bash
pip install requests tqdm pillow
```

Oder nutze bestehende `requirements.txt`:
```bash
pip install -r requirements.txt
```

## ğŸ’¾ Speicherplatz-Anforderungen

| Phase | Speicherbedarf | Beschreibung |
|-------|----------------|--------------|
| Download | ~20 GB | ZIP-Dateien |
| Extraction | ~20 GB | Extrahierte Bilder |
| Organization | ~5-10 GB | Gefilterte Kategorien |
| **GESAMT** | **~45-50 GB** | Inkl. temporÃ¤re Dateien |

### Speicherplatz reduzieren

```bash
# Nach erfolgreicher Organisation ZIP-Dateien lÃ¶schen
rm -rf coco_download/downloads/*.zip

# Nach Organisation extrahierte Originale lÃ¶schen
rm -rf coco_download/extracted/

# Nur organisierte Daten behalten (~5-10 GB)
```

## ğŸ”„ Workflow-Beispiele

### Minimaler Download (nur Val-Set fÃ¼r Tests)
```bash
# Schneller Test mit kleinerem Datensatz
python download_coco_dataset.py --splits val --categories person

python organize_training_data.py \
  --source coco_download/organized \
  --categories person \
  --train-ratio 0.6 \
  --val-ratio 0.2 \
  --test-ratio 0.2
```

### VollstÃ¤ndiger Download (alle Kategorien)
```bash
# Maximaler Datensatz
python download_coco_dataset.py \
  --splits train val \
  --categories person car bicycle motorcycle bus truck

python organize_training_data.py \
  --source coco_download/organized \
  --categories person car
```

### Zwei-Phasen Download
```bash
# Phase 1: Val-Set fÃ¼r schnelle Tests
python download_coco_dataset.py --splits val

# Phase 2: SpÃ¤ter Train-Set fÃ¼r volles Training
python download_coco_dataset.py --splits train
```

## ğŸš€ Next Steps

Nach erfolgreicher Daten-Organisation:

### 1. Daten Ã¼berprÃ¼fen
```bash
# Anzahl Bilder pro Kategorie checken
ls datatrainperson/*.jpg | wc -l
ls datatrainauto/*.jpg | wc -l
```

### 2. Training starten
```bash
cd training/
python train_model.py
```

### 3. Quick Validation Test
```python
from training.evaluate_model import ModelEvaluator
from training.train_model import TrainingConfig

config = TrainingConfig()
# Test mit einem Validierungsbild
# ...
```

## ğŸ”§ Troubleshooting

### Problem: Download zu langsam
```bash
# LÃ¶sung: Nutze Mirrors oder parallele Downloads
# Alternativ: Download manuell und extrahiere in coco_download/extracted/
```

### Problem: Nicht genug Speicherplatz
```bash
# LÃ¶sung 1: Nur Val-Set verwenden
python download_coco_dataset.py --splits val

# LÃ¶sung 2: Nach jeder Phase aufrÃ¤umen
rm -rf coco_download/downloads/
```

### Problem: Script bricht ab
```bash
# LÃ¶sung: Re-run ist sicher (Ã¼berspringt existierende Dateien)
python download_coco_dataset.py
# "âœ“ ... bereits vorhanden, Ã¼berspringe Download"
```

### Problem: Falsche Ordnerstruktur
```bash
# LÃ¶sung: Reorganisiere mit anderen Parametern
python organize_training_data.py \
  --source coco_download/organized \
  --target . \
  --train-ratio 0.8
```

## ğŸ“š Weitere Datasets (Optional)

### Gesichter-spezifisch

#### WIDER FACE
```bash
# Download von: http://shuoyang1213.me/WIDERFACE/
# Manuell in datatraingesicht/, datavalgesicht/, datatestgesicht/ organisieren
```

#### CelebA
```bash
# Download von: https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html
# Registrierung erforderlich
```

### Script fÃ¼r manuelle Integration
```python
# organize_custom_dataset.py (TODO)
# FÃ¼r Integration eigener Datasets
```

## ğŸ“– Weitere Dokumentation

- [Training Guide](training/README.md)
- [Model Evaluation](training/evaluate_model.py)
- [Vision Pipeline](core/README.md)

---

Â© 2024 AALS Software AG - LEAP-PSW Project